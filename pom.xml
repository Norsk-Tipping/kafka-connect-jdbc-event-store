<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Copyright 2018 Confluent Inc.
  ~
  ~ Licensed under the Confluent Community License (the "License"); you may not use
  ~ this file except in compliance with the License.  You may obtain a copy of the
  ~ License at
  ~
  ~ http://www.confluent.io/confluent-community-license
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
  ~ WARRANTIES OF ANY KIND, either express or implied.  See the License for the
  ~ specific language governing permissions and limitations under the License.
  -->
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">

    <modelVersion>4.0.0</modelVersion>

    <parent>
        <groupId>io.confluent</groupId>
        <artifactId>common</artifactId>
        <version>6.0.0</version>
    </parent>

    <groupId>no.norsktipping</groupId>
    <artifactId>kafka-connect-jdbc-json-connector</artifactId>
    <packaging>jar</packaging>
    <version>10.2.0</version>
    <name>kafka-connect-jdbc-json-connector</name>
    <organization>
        <name>Norsk Tipping AS</name>
        <url>http://www.norsk-tipping.no</url>
    </organization>
    <url>http://www.norsk-tipping.no</url>
    <description>
       An extension to Kafka Connect JDBC connector for storing Kafka records in RDBMS as an event store as JSON.
    </description>

    <licenses>
        <license>
            <name>Confluent Community License</name>
            <url>https://www.confluent.io/confluent-community-license</url>
            <distribution>repo</distribution>
        </license>
    </licenses>

    <properties>
        <commons-io.version>2.4</commons-io.version>
        <postgresql.version>42.2.10</postgresql.version>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <maven.compiler.source>11</maven.compiler.source>
        <maven.compiler.target>11</maven.compiler.target>
        <project.package.home>target/${project.artifactId}-${project.version}-package</project.package.home>
    </properties>

    <repositories>
        <repository>
            <id>confluent</id>
            <name>Confluent</name>
            <url>http://packages.confluent.io/maven/</url>
        </repository>
    </repositories>

    <dependencies>
        <dependency>
            <groupId>no.norsktipping</groupId>
            <artifactId>kafka-connect-converter-json</artifactId>
            <version>1.0.0</version>
        </dependency>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>connect-api</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>connect-runtime</artifactId>
            <version>${kafka.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.postgresql</groupId>
            <artifactId>postgresql</artifactId>
            <version>${postgresql.version}</version>
            <scope>runtime</scope>
        </dependency>
        <dependency>
            <groupId>com.oracle.database.jdbc</groupId>
            <artifactId>ojdbc11</artifactId>
            <version>21.3.0.0</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.easymock</groupId>
            <artifactId>easymock</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.powermock</groupId>
            <artifactId>powermock-module-junit4</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.powermock</groupId>
            <artifactId>powermock-api-easymock</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>commons-io</groupId>
            <artifactId>commons-io</artifactId>
            <version>${commons-io.version}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.mockito</groupId>
            <artifactId>mockito-all</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-log4j12</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>io.confluent</groupId>
            <artifactId>confluent-log4j</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>connect-runtime</artifactId>
            <version>${kafka.version}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>connect-runtime</artifactId>
            <version>${kafka.version}</version>
            <type>test-jar</type>
            <classifier>test</classifier>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka_${kafka.scala.version}</artifactId>
            <version>${kafka.version}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka_${kafka.scala.version}</artifactId>
            <version>${kafka.version}</version>
            <type>test-jar</type>
            <classifier>test</classifier>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>${kafka.version}</version>
            <classifier>test</classifier>
            <type>test-jar</type>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>io.confluent</groupId>
            <artifactId>kafka-connect-maven-plugin</artifactId>
            <version>0.12.0</version>
        </dependency>
        <dependency>
            <groupId>com.google.code.gson</groupId>
            <artifactId>gson</artifactId>
            <version>2.8.6</version>
        </dependency>
    </dependencies>

    <build>
    <pluginManagement>
        <plugins>
            <plugin>
                <groupId>io.confluent</groupId>
                <artifactId>kafka-connect-maven-plugin</artifactId>
                <version>0.12.0</version>
            </plugin>
        </plugins>
    </pluginManagement>
        <plugins>
            <plugin>
                <groupId>io.confluent</groupId>
                <version>0.12.0</version>
                <artifactId>kafka-connect-maven-plugin</artifactId>
                <executions>
                    <execution>
                        <goals>
                            <goal>kafka-connect</goal>
                        </goals>
                        <phase>none</phase>
                        <configuration>
                            <title>Kafka Connect JDBC RDBMS JSON Event Store</title>
                            <documentationUrl>https://github.com/gertschouten/kafka-connect-jdbc-json-connector</documentationUrl>
                            <description>
                                The Kafka Connect JDBC RDBMS JSON Event Store sink connector allows you to export data from Kafka topics in JSON or Avro format
                                to the following supported RDBMSs (Netezza Performance Server, Oracle Exadata, Postgresql).
                                The connector polls data from Kafka to write to the database based on the topics subscription.
                                The connector supports the different subject naming strategies in case of Avro and is therefore capable of handling multiple Avro
                                schema structures. In case of a source topic where messages are serialized as JSON, the connector allows schema-less consumption.

                                The sink connector stores the messages as JSON datatype in the target system (JSONB in case of Netezza Performance Server and
                                Postgresql, BLOB in case of Oracle Exadata).
                                By configuration you define fields you want to have extracted to their own target columns.
                                Indexing on these columns is handled with Big Data indexing features e.g. zonemaps, partitioning, clustering, bloom filtering.
                                This should allow for higher insert performance than traditional B-tree indexing while at the same time
                                limiting table scans on point queries, range queries and set queries.

                                The combination of JSON serialized target values for the message values and indexed columns as meta-data for the messages makes
                                this sink connector a candidate for Event store patterns.

                                In principal, the common insert mode is Insert. However, it is possible to achieve idempotent writes with Upsert mode.
                                Deletes and Update insert modes are alo supported.
                                Auto-creation of tables, and limited auto-evolution is also supported.
                            </description>
                            <logo>logos/jdbc.png</logo>

                            <ownerUsername>norsktipping</ownerUsername>
                            <ownerType>organization</ownerType>
                            <ownerName>Norsk Tipping AS</ownerName>
                            <ownerUrl>https://www.norsk-tipping.no/selskapet/engelsk</ownerUrl>
                            <ownerLogo>logos/nt.png</ownerLogo>

                            <componentTypes>
                                <componentType>sink</componentType>
                            </componentTypes>

                            <tags>
                                <tag>jdbc</tag>
                                <tag>database</tag>
                                <tag>dbms</tag>
                                <tag>rdbms</tag>
                                <tag>postgresql</tag>
                                <tag>oracle</tag>
                                <tag>netezza</tag>
                                <tag>json</tag>
                            </tags>

                            <confluentControlCenterIntegration>true</confluentControlCenterIntegration>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-checkstyle-plugin</artifactId>
                <executions>
                    <execution>
                        <id>validate</id>
<!--                        <phase>validate</phase>-->
                        <phase>none</phase>
                        <configuration>
                            <suppressionsLocation>checkstyle/suppressions.xml</suppressionsLocation>
                        </configuration>
                        <goals>
                            <goal>check</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
                <version>3.2.4</version>
                <executions>
                    <execution>
                        <phase>package</phase>
                        <goals>
                            <goal>shade</goal>
                        </goals>
                        <configuration>
                            <transformers>
                                <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
                                    <mainClass>no.norsktipping.kafka.connect.jdbc.jsonconnector.JdbcSinkConnector</mainClass>
                                </transformer>
                            </transformers>
                            <finalName>norsktipping-${project.artifactId}-${project.version}</finalName>
                            <outputDirectory>target</outputDirectory>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
        <resources>
            <resource>
                <directory>src/main/resources</directory>
                <filtering>true</filtering>
            </resource>
        </resources>
    </build>
</project>
